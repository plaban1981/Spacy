{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy_Fundamentals.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gZZFaqbJEEZf",
        "ylbFZ9-IEdyu",
        "dnzO86y9EXvW",
        "NGGEPUO1EkRt",
        "eHGW7rlaFQlH",
        "fK5YGKgfF-oM",
        "xf4sX5kpGaG-",
        "GESD4sRpG5fY",
        "1jbwdyZHOKZj",
        "39r_ihpPQpvz",
        "FVpACQk5U68k",
        "N6sDq0OnWMOR",
        "6eeKrxO0X2KU",
        "FF-Ps_ipZ-WD",
        "EYC771v6crZy",
        "NcNSAh6OfclI",
        "956wv9oQflW_",
        "4hsmik5sgEKt",
        "m1AWuj80iCCX",
        "L49upKGHjR2A",
        "WfazKaqflDK3",
        "TAPzXJGDpWAy",
        "nFFlyJ12qed6",
        "KCNJDi9XqqER"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Spacy/blob/master/Spacy_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LREr42W-bam",
        "colab_type": "text"
      },
      "source": [
        "## Import spaCy and load the language library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpYI86Os9AVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkpGG8S5_ZzJ",
        "colab_type": "text"
      },
      "source": [
        "## spaCy Objects\n",
        "\n",
        "After importing the spacy module in the cell above we loaded a model and named it nlp.\n",
        "\n",
        "Next we created a Doc object by applying the model to our text, and named it doc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTl9EsNZ-rn7",
        "colab_type": "text"
      },
      "source": [
        "## Create a Document Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XfA78iy-v79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmHv1EXJ-2_P",
        "colab_type": "code",
        "outputId": "e9768bbc-6330-4684-f306-9f52ec1947f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "for text in doc:\n",
        "  print(text.text,'---',text.pos_,'---',text.dep_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla --- PROPN --- nsubj\n",
            "is --- VERB --- aux\n",
            "looking --- VERB --- ROOT\n",
            "at --- ADP --- prep\n",
            "buying --- VERB --- pcomp\n",
            "U.S. --- PROPN --- compound\n",
            "startup --- NOUN --- dobj\n",
            "for --- ADP --- prep\n",
            "$ --- SYM --- quantmod\n",
            "6 --- NUM --- compound\n",
            "million --- NUM --- pobj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNoIe8VDAVey",
        "colab_type": "text"
      },
      "source": [
        "##Pipeline\n",
        "\n",
        "When we run nlp, our text enters a processing pipeline that first breaks down the text and then performs a series of operations \n",
        "- to tag, ==> Tagger \n",
        "- parse and ==> Parser\n",
        "- describe the data. ==> Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUsZ0AgKAkCO",
        "colab_type": "code",
        "outputId": "be612244-ec6b-4a35-a313-363ec2e33a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nlp.pipeline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7fd546028588>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fd5434e5b88>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7fd5434e5be8>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxYgpkPmBVqL",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "The first step in processing text is to split up all the component parts (words & punctuation) into \"tokens\". These tokens are annotated inside the Doc object to contain descriptive information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjuxvDFlCQ9A",
        "colab_type": "code",
        "outputId": "9b789330-04fa-4506-c19e-6e3c455aa9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0],doc[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Tesla, looking)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKCpeasCC5Cl",
        "colab_type": "text"
      },
      "source": [
        "## POS - Parts of Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MosiCQWxC--u",
        "colab_type": "code",
        "outputId": "08ca02db-f949-4fe8-8ea5-a5a55b6065bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].pos_,doc[2].pos_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('PROPN', 'VERB')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu6rhWSuDS3i",
        "colab_type": "text"
      },
      "source": [
        "##Dependencies\n",
        "We also looked at the syntactic dependencies assigned to each token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2sQgQExDVF8",
        "colab_type": "code",
        "outputId": "3dc790e4-b5c5-4964-9f8b-22607f385bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].dep_,doc[2].dep_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('nsubj', 'ROOT')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC4MCI00Dj0f",
        "colab_type": "text"
      },
      "source": [
        "##To see the full name of a tag use spacy.explain(tag)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OreBxZAsDlFP",
        "colab_type": "code",
        "outputId": "fcc7d148-2489-4bc6-c9de-ea9058a22a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spacy.explain('nsubj'),spacy.explain('ROOT'),spacy.explain('PROPN')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('nominal subject', None, 'proper noun')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZZFaqbJEEZf",
        "colab_type": "text"
      },
      "source": [
        "##Additional Token Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylbFZ9-IEdyu",
        "colab_type": "text"
      },
      "source": [
        "## text - The original word text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCHg9lSjEHQy",
        "colab_type": "code",
        "outputId": "66e35b19-dcbc-4ed8-f643-cbdd360a78cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].text,doc[2].text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Tesla', 'looking')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnzO86y9EXvW",
        "colab_type": "text"
      },
      "source": [
        "##lemma - The base form of the word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt6ypUYtEOYD",
        "colab_type": "code",
        "outputId": "cce8f7a2-5ea8-40b2-a61a-44cef741b6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].lemma_,doc[2].lemma_,doc[5].lemma_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Tesla', 'look', 'U.S.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGEPUO1EkRt",
        "colab_type": "text"
      },
      "source": [
        "##pos_ - The simple part-of-speech tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0LNJD8vEmYW",
        "colab_type": "code",
        "outputId": "1d3e5996-5929-481a-a7af-f73d4ac3e98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].pos_,doc[5].pos_,doc[5].pos_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('PROPN', 'PROPN', 'PROPN')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHGW7rlaFQlH",
        "colab_type": "text"
      },
      "source": [
        "## tag_ - The detailed part-of-speech tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBFjmmesFUWm",
        "colab_type": "code",
        "outputId": "7b53540a-9633-48f1-b6f8-951f01e003a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].tag_,doc[5].tag_,doc[5].tag_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('NNP', 'NNP', 'NNP')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK5YGKgfF-oM",
        "colab_type": "text"
      },
      "source": [
        "## Shape - The word shape – capitalization, punctuation, digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdkJeqP6GFUC",
        "colab_type": "code",
        "outputId": "279e228e-ab32-46b1-b1c3-9a7d7412f209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].shape_,doc[5].shape_,doc[5].shape_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Xxxxx', 'X.X.', 'X.X.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf4sX5kpGaG-",
        "colab_type": "text"
      },
      "source": [
        "##is_alpha - Is the token an alpha character?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FDrcwUeGfpp",
        "colab_type": "code",
        "outputId": "7221085b-4cbb-4682-81e1-015129652d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].is_alpha,doc[5].is_alpha,doc[5].is_alpha"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, False, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GESD4sRpG5fY",
        "colab_type": "text"
      },
      "source": [
        "## is_stop - Is the token part of a stop list, i.e. the most common words of the language?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GXNOiJkG39N",
        "colab_type": "code",
        "outputId": "45962de3-01a1-4746-9a6e-c85a62a8ce8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc[0].is_stop,doc[5].is_stop,doc[5].is_stop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, False, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jbwdyZHOKZj",
        "colab_type": "text"
      },
      "source": [
        "##Spans\n",
        "Large Doc objects can be hard to work with at times. \n",
        "\n",
        "A span is a slice of Doc object in the form Doc[start:stop]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2_T5QqXOs0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
        "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
        "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmSMndFePTIC",
        "colab_type": "code",
        "outputId": "1327c4e6-9930-4d7a-e85f-a1ac3550916b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "doc3.text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", the phrase \"Life is what happens to us while we are making other plans\" was written by cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8zQZxW1PnYb",
        "colab_type": "code",
        "outputId": "d58c3cb6-9b2f-4f00-8aff-a92eba7882dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "life_quote = doc3[16:30]\n",
        "print(life_quote)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Life is what happens to us while we are making other plans\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfN__HsmPz3_",
        "colab_type": "code",
        "outputId": "0e73c1ae-dad0-4192-88a7-e1f69dcd2a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(life_quote)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39r_ihpPQpvz",
        "colab_type": "text"
      },
      "source": [
        "##Sentences - Doc.sents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PyEiFVzQuaw",
        "colab_type": "code",
        "outputId": "e1bb856e-bdfc-46a1-ef56-9f3d4882c545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "doc4 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
        "for sentences in doc4.sents:\n",
        "  print(sentences)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the first sentence.\n",
            "\n",
            "\n",
            "This is another sentence.\n",
            "\n",
            "\n",
            "This is the last sentence.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVpACQk5U68k",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization\n",
        "The first step in creating a Doc object is to break down the incoming text into component pieces or \"tokens\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Zq-6VTVisZ",
        "colab_type": "code",
        "outputId": "97a020e6-da28-407a-99bf-cfb2b58940ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mystring = '\"We\\'re moving to L.A.!\"'\n",
        "print(mystring)\n",
        "doc = nlp(mystring)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, end=' | ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"We're moving to L.A.!\"\n",
            "\" | We | 're | moving | to | L.A. | ! | \" | "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6sDq0OnWMOR",
        "colab_type": "text"
      },
      "source": [
        "##Prefixes, Suffixes and Infixes\n",
        "spaCy will isolate punctuation that does not form an integral part of a word. Quotation marks, commas, and punctuation at the end of a sentence will be assigned their own token. However, punctuation that exists as part of an email address, website or numerical value will be kept as part of the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPQLGoTyXCje",
        "colab_type": "code",
        "outputId": "9228d282-50a1-41b9-a498-3aa6fdac4760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "doc2 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n",
        "\n",
        "for t in doc2:\n",
        "    print(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We\n",
            "'re\n",
            "here\n",
            "to\n",
            "help\n",
            "!\n",
            "Send\n",
            "snail\n",
            "-\n",
            "mail\n",
            ",\n",
            "email\n",
            "support@oursite.com\n",
            "or\n",
            "visit\n",
            "us\n",
            "at\n",
            "http://www.oursite.com\n",
            "!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eeKrxO0X2KU",
        "colab_type": "text"
      },
      "source": [
        "#### Note that the exclamation points, comma, and the hyphen in 'snail-mail' are assigned their own tokens, yet both the email address and website are preserved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRYPrxKoX7W-",
        "colab_type": "code",
        "outputId": "93323411-4a90-473f-9cde-d78c28b7ac9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "doc3 = nlp(u'A 5km NYC cab ride costs $10.30')\n",
        "\n",
        "for t in doc3:\n",
        "    print(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A\n",
            "5\n",
            "km\n",
            "NYC\n",
            "cab\n",
            "ride\n",
            "costs\n",
            "$\n",
            "10.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF-Ps_ipZ-WD",
        "colab_type": "text"
      },
      "source": [
        "####Here the distance unit and dollar sign are assigned their own tokens, yet the dollar amount is preserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYC771v6crZy",
        "colab_type": "text"
      },
      "source": [
        "##Exceptions\n",
        "Punctuation that exists as part of a known abbreviation will be kept as part of the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kvfZV6yaNZU",
        "colab_type": "code",
        "outputId": "8ae25243-6902-4074-ccba-0fb27630b6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "doc4 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
        "\n",
        "for t in doc4:\n",
        "    print(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let\n",
            "'s\n",
            "visit\n",
            "St.\n",
            "Louis\n",
            "in\n",
            "the\n",
            "U.S.\n",
            "next\n",
            "year\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcNSAh6OfclI",
        "colab_type": "text"
      },
      "source": [
        "##Counting Tokens - Doc objects have a set number of tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K0atHxofd5V",
        "colab_type": "code",
        "outputId": "1f2cd7de-b2af-4248-adfe-75988d499d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(doc3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "956wv9oQflW_",
        "colab_type": "text"
      },
      "source": [
        "## Counting Vocab Entries - Vocab objects contain a full library of items!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i8uNYVvfqkj",
        "colab_type": "code",
        "outputId": "33b85a12-9a2b-4b8a-8ec2-ae41f6bb6046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(doc3.vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "551"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hsmik5sgEKt",
        "colab_type": "text"
      },
      "source": [
        "##Tokens can be retrieved by index position and slice\n",
        "\n",
        "Doc objects can be thought of as lists of token objects. As such, individual tokens can be retrieved by index position, and spans of tokens can be retrieved through slicing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmuRCLsUgKV2",
        "colab_type": "code",
        "outputId": "12d2944a-8a8a-414d-9db6-5b30e4dfebfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc5 = nlp(u'It is better to give than to receive.')\n",
        "\n",
        "# Retrieve the third token:\n",
        "doc5[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "better"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xN0V77VgNth",
        "colab_type": "code",
        "outputId": "42b538f3-31a1-4310-d362-24d40be0716e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Retrieve three tokens from the middle:\n",
        "doc5[2:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "better to give"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1AWuj80iCCX",
        "colab_type": "text"
      },
      "source": [
        "##Tokens cannot be reassigned\n",
        "Although Doc objects can be considered lists of tokens, they do not support item reassignment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsHvD-K8jCO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc6 = nlp(u'My dinner was horrible.')\n",
        "doc7 = nlp(u'Your dinner was delicious.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHIxssv_jJj-",
        "colab_type": "code",
        "outputId": "a017b8c8-d3b0-427f-c680-ab993a68f15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "# Try to change \"My dinner was horrible\" to \"My dinner was delicious\"\n",
        "doc6[3] = doc7[3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c84f13888331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L49upKGHjR2A",
        "colab_type": "text"
      },
      "source": [
        "##Named Entities\n",
        "The language model recognizes that certain words are organizational names while others are locations, and still other combinations relate to money, dates, etc. Named entities are accessible through the ents property of a Doc object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Eq8Hldjb4p",
        "colab_type": "code",
        "outputId": "8d8e8e33-b49c-4db0-b290-3189ed74bc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
        "for token in doc8:\n",
        "    print(token.text, end=' | ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRgyPiaVkU8-",
        "colab_type": "code",
        "outputId": "2d64e21b-19df-42ad-9ca5-f588e51c9a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc8.ents"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Apple, Hong Kong, $6 million)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9WLMwvGkQmC",
        "colab_type": "code",
        "outputId": "a5fa5590-dee7-4034-e585-a31f6c9a6a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "for ent in doc8.ents:\n",
        "    print(ent.text+' --- '+ent.label_+' --- '+str(spacy.explain(ent.label_)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple --- ORG --- Companies, agencies, institutions, etc.\n",
            "Hong Kong --- GPE --- Countries, cities, states\n",
            "$6 million --- MONEY --- Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht8_TvAKky2b",
        "colab_type": "code",
        "outputId": "151db726-b441-46c4-c35b-af841cb0c6e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(doc8.ents)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfazKaqflDK3",
        "colab_type": "text"
      },
      "source": [
        "##Noun Chunks\n",
        "Similar to Doc.ents, Doc.noun_chunks are another object property. Noun chunks are \"base noun phrases\" – flat phrases that have a noun as their head. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnfegpb-lJCV",
        "colab_type": "code",
        "outputId": "4ade99aa-9c85-4b42-ca53-ec983cf5c060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
        "\n",
        "for chunk in doc9.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autonomous cars\n",
            "insurance liability\n",
            "manufacturers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM537rQ3l70j",
        "colab_type": "code",
        "outputId": "534e4449-f562-47fa-ffc3-1f061a4fc0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "doc10 = nlp(u\"Red cars do not carry higher insurance rates.\")\n",
        "\n",
        "for chunk in doc10.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Red cars\n",
            "higher insurance rates\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jawFmrW4mQYm",
        "colab_type": "code",
        "outputId": "21787121-2991-4487-d51a-44f4be128bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "doc11 = nlp(u\"He was a one-eyed, one-horned, flying, purple people-eater.\")\n",
        "\n",
        "for chunk in doc11.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He\n",
            "a one-eyed, one-horned, flying, purple people-eater\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAPzXJGDpWAy",
        "colab_type": "text"
      },
      "source": [
        "##Built-in Visualizers\n",
        "\n",
        "spaCy includes a built-in visualization tool called displaCy. \n",
        "\n",
        "displaCy is able to detect whether you're working in a Jupyter notebook, and will return markup that can be rendered in a cell right away. W\n",
        "\n",
        "hen you export your notebook, the visualizations will be included as HTML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2BVvWoKpdZ1",
        "colab_type": "code",
        "outputId": "6f7c7e8b-349e-4135-e0f4-62ceddd861db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"22f395b15238490299c8426bea3e19d2-0\" class=\"displacy\" width=\"1370\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">U.K.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">factory</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">6</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">million.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,112.0 810.0,112.0 810.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-6\" stroke-width=\"2px\" d=\"M510,222.0 C510,57.0 815.0,57.0 815.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M815.0,224.0 L823.0,212.0 807.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-7\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L938.0,212.0 922.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-8\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,112.0 1250.0,112.0 1250.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1060,224.0 L1052,212.0 1068,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,167.0 1245.0,167.0 1245.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22f395b15238490299c8426bea3e19d2-0-10\" stroke-width=\"2px\" d=\"M950,222.0 C950,57.0 1255.0,57.0 1255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22f395b15238490299c8426bea3e19d2-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1255.0,224.0 L1263.0,212.0 1247.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFFlyJ12qed6",
        "colab_type": "text"
      },
      "source": [
        "#### Note:\n",
        "The optional 'distance' argument sets the distance between tokens. If the distance is made too small, text that appears beneath short arrows may become too compressed to read."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCNJDi9XqqER",
        "colab_type": "text"
      },
      "source": [
        "##Visualizing the entity recognizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1HGoO0oqpbY",
        "colab_type": "code",
        "outputId": "32632af2-131e-4259-802c-b78e5ae4ee3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    the last quarter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " sold \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    nearly 20 thousand\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " iPods for a profit of \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    $6 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWK49ER6rGgh",
        "colab_type": "text"
      },
      "source": [
        "##Creating Visualizations Outside of Jupyter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPfn9UE1rHjQ",
        "colab_type": "code",
        "outputId": "4a918744-01be-4025-cf13-05602017de20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "doc = nlp(u'This is a sentence.')\n",
        "displacy.serve(doc, style='dep')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIdK_uz4spV8",
        "colab_type": "text"
      },
      "source": [
        "##Stemming\n",
        "Stemming is a somewhat crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached. This works fairly well in most cases, but unfortunately English has many exceptions where a more sophisticated process is required. \n",
        "\n",
        "**In fact, spaCy doesn't include a stemmer, opting instead to rely entirely on lemmatization.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMFNLjkfto8r",
        "colab_type": "text"
      },
      "source": [
        "##PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-5KgAtdtlcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the toolkit and the full Porter Stemmer library\n",
        "import nltk\n",
        "\n",
        "from nltk.stem.porter import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhOyL7t_tr3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_stemmer = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzxVBJfitwwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f3a0db14-ca11-4d05-9c98-5a87b4d2f0f8"
      },
      "source": [
        "words = ['run','runner','running','ran','runs','easily','fairly']\n",
        "for word in words:\n",
        "  print(word+ ' ---> '+p_stemmer.stem(word))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run ---> run\n",
            "runner ---> runner\n",
            "running ---> run\n",
            "ran ---> ran\n",
            "runs ---> run\n",
            "easily ---> easili\n",
            "fairly ---> fairli\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09j_14uZuWc8",
        "colab_type": "text"
      },
      "source": [
        "##Snowball Stemmer\n",
        "\n",
        "This is somewhat of a misnomer, as Snowball is the name of a stemming language developed by Martin Porter. The algorithm used here is more acurately called the \"English Stemmer\" or \"Porter2 Stemmer\". It offers a slight improvement over the original Porter stemmer, both in logic and speed. Since nltk uses the name SnowballStemmer, we'll use it here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pJdCQAHutbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d7145e76-68b7-491f-b6eb-b9a9669e9809"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "s_stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "for word in words:\n",
        "  print(word + '---> '+s_stemmer.stem(word))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run---> run\n",
            "runner---> runner\n",
            "running---> run\n",
            "ran---> ran\n",
            "runs---> run\n",
            "easily---> easili\n",
            "fairly---> fair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRZodpDPwwoV",
        "colab_type": "text"
      },
      "source": [
        "##Stemming has its drawbacks. \n",
        "\n",
        "If given the token **saw**, **stemming** might always return **saw**, whereas **lemmatization** would likely return either **see** or **saw** depending on whether the use of the token was as a verb or a noun. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K71Q3c_hxb-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3d4fb5b6-0c09-412e-d48f-c1f805373ba0"
      },
      "source": [
        "phrase = 'I am meeting him tomorrow at the meeting'\n",
        "for word in phrase.split():\n",
        "    print(word+' --> '+p_stemmer.stem(word))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I --> I\n",
            "am --> am\n",
            "meeting --> meet\n",
            "him --> him\n",
            "tomorrow --> tomorrow\n",
            "at --> at\n",
            "the --> the\n",
            "meeting --> meet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmgZjZi6x2aM",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatization\n",
        "In contrast to stemming, lemmatization looks beyond word reduction, and considers a language's full vocabulary to apply a morphological analysis to words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwbe-Trsypt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0169482a-b475-4640-fc04-a0674ed97502"
      },
      "source": [
        "doc_1 = nlp(u'I am meeting him tomorrow at the meeting')\n",
        "for token in doc_1:\n",
        "  print(token.text, '\\t', token.pos_, '\\t', token.lemma, '\\t', token.lemma_)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I \t PRON \t 561228191312463089 \t -PRON-\n",
            "am \t VERB \t 10382539506755952630 \t be\n",
            "meeting \t VERB \t 6880656908171229526 \t meet\n",
            "him \t PRON \t 561228191312463089 \t -PRON-\n",
            "tomorrow \t NOUN \t 3573583789758258062 \t tomorrow\n",
            "at \t ADP \t 11667289587015813222 \t at\n",
            "the \t DET \t 7425985699627899538 \t the\n",
            "meeting \t NOUN \t 14798207169164081740 \t meeting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK2gSWzj1FGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e1cf366b-636c-49d5-d5e8-be12ab8d71f4"
      },
      "source": [
        "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
        "\n",
        "for token in doc1:\n",
        "    print(token.text, '\\t', token.pos_, '\\t', token.lemma, '\\t', token.lemma_)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I \t PRON \t 561228191312463089 \t -PRON-\n",
            "am \t VERB \t 10382539506755952630 \t be\n",
            "a \t DET \t 11901859001352538922 \t a\n",
            "runner \t NOUN \t 12640964157389618806 \t runner\n",
            "running \t VERB \t 12767647472892411841 \t run\n",
            "in \t ADP \t 3002984154512732771 \t in\n",
            "a \t DET \t 11901859001352538922 \t a\n",
            "race \t NOUN \t 8048469955494714898 \t race\n",
            "because \t ADP \t 16950148841647037698 \t because\n",
            "I \t PRON \t 561228191312463089 \t -PRON-\n",
            "love \t VERB \t 3702023516439754181 \t love\n",
            "to \t PART \t 3791531372978436496 \t to\n",
            "run \t VERB \t 12767647472892411841 \t run\n",
            "since \t ADP \t 10066841407251338481 \t since\n",
            "I \t PRON \t 561228191312463089 \t -PRON-\n",
            "ran \t VERB \t 12767647472892411841 \t run\n",
            "today \t NOUN \t 11042482332948150395 \t today\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t0ait_Q1NPn",
        "colab_type": "text"
      },
      "source": [
        "##Function to display lemmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkYtQyRC1Ohu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_lemmas(text):\n",
        "  for token in text:\n",
        "    print(f'{token.text:{12}}{token.pos_:{6}}{token.lemma:<{22}}{token.lemma_}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l9aRVf39KT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4babd118-dfc6-4c61-9c7d-2241556bcdbb"
      },
      "source": [
        "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
        "show_lemmas(doc2)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I           PRON  561228191312463089    -PRON-\n",
            "saw         VERB  11925638236994514241  see\n",
            "eighteen    NUM   9609336664675087640   eighteen\n",
            "mice        NOUN  1384165645700560590   mouse\n",
            "today       NOUN  11042482332948150395  today\n",
            "!           PUNCT 17494803046312582752  !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gdHmZS99f9Q",
        "colab_type": "text"
      },
      "source": [
        "#### Notice that the lemma of saw is see, mice is the plural form of mouse, and yet eighteen is its own number, not an expanded form of eight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnnE9ljp-VIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "bb3e89e0-516e-40bc-e864-457a71829320"
      },
      "source": [
        "doc3 = nlp(u\"I am meeting him tomorrow at the meeting.\")\n",
        "show_lemmas(doc3)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I           PRON  561228191312463089    -PRON-\n",
            "am          VERB  10382539506755952630  be\n",
            "meeting     VERB  6880656908171229526   meet\n",
            "him         PRON  561228191312463089    -PRON-\n",
            "tomorrow    NOUN  3573583789758258062   tomorrow\n",
            "at          ADP   11667289587015813222  at\n",
            "the         DET   7425985699627899538   the\n",
            "meeting     NOUN  14798207169164081740  meeting\n",
            ".           PUNCT 12646065887601541794  .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3kk8XzgDnwa",
        "colab_type": "text"
      },
      "source": [
        "##Here the lemma of meeting is determined by its Part of Speech tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv-bq2jkDmhq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "73aa9aa1-5edd-44ee-b516-07f07c765462"
      },
      "source": [
        "doc4 = nlp(u\"That's an enormous automobile\")\n",
        "show_lemmas(doc4)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "That        DET   4380130941430378203   that\n",
            "'s          VERB  10382539506755952630  be\n",
            "an          DET   15099054000809333061  an\n",
            "enormous    ADJ   17917224542039855524  enormous\n",
            "automobile  NOUN  7211811266693931283   automobile\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbue6eXD-5a",
        "colab_type": "text"
      },
      "source": [
        "####Note that lemmatization does not reduce words to their most basic synonym - that is, enormous doesn't become big and automobile doesn't become car."
      ]
    }
  ]
}